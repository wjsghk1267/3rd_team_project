{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 에코"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 비디오 폴더 경로 설정\n",
    "VIDEO_FOLDER = \"E:/dog_videos/\"\n",
    "\n",
    "# 문장 임베딩을 위한 모델 로드\n",
    "sentence_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def compare_results(echo_result, gpt4o_result):\n",
    "    # 텍스트 임베딩 생성\n",
    "    echo_embedding = sentence_model.encode([echo_result])\n",
    "    gpt4o_embedding = sentence_model.encode([gpt4o_result])\n",
    "\n",
    "    # 코사인 유사도 계산\n",
    "    similarity = cosine_similarity(echo_embedding, gpt4o_embedding)[0][0]\n",
    "\n",
    "    # 키워드 추출 및 비교\n",
    "    echo_keywords = set(echo_result.lower().split())\n",
    "    gpt4o_keywords = set(gpt4o_result.lower().split())\n",
    "\n",
    "    common_keywords = echo_keywords.intersection(gpt4o_keywords)\n",
    "    unique_echo = echo_keywords - gpt4o_keywords\n",
    "    unique_gpt4o = gpt4o_keywords - echo_keywords\n",
    "\n",
    "    return {\n",
    "        \"similarity\": similarity,\n",
    "        \"common_keywords\": list(common_keywords),\n",
    "        \"unique_echo\": list(unique_echo),\n",
    "        \"unique_gpt4o\": list(unique_gpt4o)\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    results = []\n",
    "\n",
    "    for video_file in os.listdir(VIDEO_FOLDER):\n",
    "        if video_file.endswith(('.mp4', '.avi', '.mov')):  # 비디오 파일 확장자\n",
    "            video_path = os.path.join(VIDEO_FOLDER, video_file)\n",
    "            print(f\"처리 중인 비디오: {video_file}\")\n",
    "\n",
    "            # 기존의 분석 코드 (YOLO, LSTM, LLM 등)\n",
    "            # ...\n",
    "\n",
    "            # Echo Demo 분석 결과\n",
    "            echo_result = generate_comprehensive_analysis(yolo_text, lstm_text, summary_text, rag_text)\n",
    "\n",
    "            # GPT-4o-mini 분석 결과\n",
    "            gpt4o_prompt = f\"\"\"\n",
    "            강아지 영상 분석 결과:\n",
    "            1. YOLO 모델 (품종 탐지): {yolo_text}\n",
    "            2. LSTM 모델 (행동 분석): {lstm_text}\n",
    "            3. 비디오 요약: {summary_text}\n",
    "\n",
    "            위 정보를 바탕으로 강아지의 상태, 행동, 감정에 대해 종합적으로 분석해주세요.\n",
    "            \"\"\"\n",
    "            gpt4o_response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini-2024-07-18\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"당신은 강아지 행동 분석 전문가입니다.\"},\n",
    "                    {\"role\": \"user\", \"content\": gpt4o_prompt}\n",
    "                ],\n",
    "                max_tokens=150\n",
    "            )\n",
    "            gpt4o_result = gpt4o_response.choices[0].message.content\n",
    "\n",
    "            # 결과 비교\n",
    "            comparison = compare_results(echo_result, gpt4o_result)\n",
    "            results.append({\n",
    "                \"video\": video_file,\n",
    "                \"echo_result\": echo_result,\n",
    "                \"gpt4o_result\": gpt4o_result,\n",
    "                \"comparison\": comparison\n",
    "            })\n",
    "\n",
    "            print(f\"비디오 {video_file} 처리 완료\")\n",
    "            print(\"유사도:\", comparison[\"similarity\"])\n",
    "            print(\"공통 키워드:\", \", \".join(comparison[\"common_keywords\"][:10]))  # 처음 10개만 출력\n",
    "            print(\"Echo Demo 고유 키워드:\", \", \".join(comparison[\"unique_echo\"][:10]))\n",
    "            print(\"GPT-4o-mini 고유 키워드:\", \", \".join(comparison[\"unique_gpt4o\"][:10]))\n",
    "            print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    # 전체 결과 요약\n",
    "    avg_similarity = sum(r['comparison']['similarity'] for r in results) / len(results)\n",
    "    total_common_keywords = set()\n",
    "    total_unique_echo = set()\n",
    "    total_unique_gpt4o = set()\n",
    "\n",
    "    for r in results:\n",
    "        total_common_keywords.update(r['comparison']['common_keywords'])\n",
    "        total_unique_echo.update(r['comparison']['unique_echo'])\n",
    "        total_unique_gpt4o.update(r['comparison']['unique_gpt4o'])\n",
    "\n",
    "    print(\"=== 전체 평가 결과 ===\")\n",
    "    print(f\"평균 유사도: {avg_similarity:.4f}\")\n",
    "    print(f\"총 공통 키워드 수: {len(total_common_keywords)}\")\n",
    "    print(f\"Echo Demo 총 고유 키워드 수: {len(total_unique_echo)}\")\n",
    "    print(f\"GPT-4o-mini 총 고유 키워드 수: {len(total_unique_gpt4o)}\")\n",
    "\n",
    "    # 결과를 JSON 파일로 저장\n",
    "    with open('analysis_results.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.51.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\administrator\\appdata\\roaming\\python\\python310\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\administrator\\appdata\\roaming\\python\\python310\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\administrator\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 분석 결과:\n",
      "[품종]: 알수없음,  \n",
      "[행동]: 고양이는 주로 앉아 있거나 엎드린 자세로 안정된 상태를 유지하며 주위를 살피고 있다.  \n",
      "[감정]: 고양이는 긴장을 풀고 편안한 상태로 보이며, 주위를 탐색하는 모습에서 호기심이 느껴진다.  \n",
      "[질병/통증]: 전반적으로 움직임이 부드럽고 자연스럽기 때문에 질병이나 통증의 징후는 보이지 않는다.  \n",
      "[비정상행동]: 비정상적인 행동은 발견되지 않으며, 정상적인 고양이 행동을 보인다.  \n",
      "\n",
      "실제 메타데이터:\n",
      "{\n",
      "  \"seq\": 156,\n",
      "  \"species\": \"CAT\",\n",
      "  \"action\": \"허리를 아치로 세움\",\n",
      "  \"location\": \"실내\",\n",
      "  \"height\": 1440,\n",
      "  \"width\": 1440,\n",
      "  \"duration\": 17.408,\n",
      "  \"animal\": {\n",
      "    \"breed\": \"코리안 숏헤어\",\n",
      "    \"gender\": \"FEMALE\",\n",
      "    \"age\": 1,\n",
      "    \"neuter\": \"Y\"\n",
      "  },\n",
      "  \"owner\": {\n",
      "    \"pain\": \"N\",\n",
      "    \"disease\": \"N\",\n",
      "    \"emotion\": \"화남/불쾌\",\n",
      "    \"situation\": \"낯선 장소에 있거나 낯선 소리가 날 때\",\n",
      "    \"animalCount\": 1\n",
      "  },\n",
      "  \"inspect\": {\n",
      "    \"action\": \"허리를 아치로 세움\",\n",
      "    \"painDisease\": \"N\",\n",
      "    \"abnormalAction\": \"N\",\n",
      "    \"emotion\": \"화남/불쾌\"\n",
      "  }\n",
      "}\n",
      "\n",
      "비교 분석:\n",
      "실제 행동: 허리를 아치로 세움\n",
      "실제 감정: 화남/불쾌\n",
      "통증/질병 여부: N\n",
      "비정상 행동 여부: N\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from collections import Counter\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def process_yolo_results(results):\n",
    "    lstm_keypoint_sequence = []\n",
    "    skeleton_sequence = []\n",
    "    breed_counter = Counter()\n",
    "\n",
    "    for r in results:\n",
    "        if r.keypoints is not None and len(r.keypoints) > 0:\n",
    "            yolo_keypoints = r.keypoints[0].cpu().numpy()\n",
    "            lstm_keypoints = convert_yolo_to_lstm(yolo_keypoints)\n",
    "            lstm_keypoint_sequence.append(lstm_keypoints)\n",
    "            skeleton = create_skeleton(lstm_keypoints)\n",
    "            skeleton_sequence.append(skeleton)\n",
    "\n",
    "            # YOLO 결과에서 품종 정보 추출 및 카운트\n",
    "            boxes = r.boxes\n",
    "            for box in boxes:\n",
    "                cls = int(box.cls[0])\n",
    "                class_name = r.names[cls]\n",
    "                breed_counter[class_name] += 1  # 품종 등장 횟수 증가\n",
    "\n",
    "    return np.array(lstm_keypoint_sequence), np.array(skeleton_sequence), breed_counter\n",
    "\n",
    "\n",
    "def analyze_keypoints_with_llm(json_data):\n",
    "    # 키포인트 정보만 추출\n",
    "    annotations = json_data['annotations']\n",
    "    \n",
    "    # 키포인트 데이터 문자열 생성 (전체 프레임)\n",
    "    keypoints_str = json.dumps(annotations, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    # LLM에 전달할 프롬프트 생성\n",
    "    prompt = f\"\"\"\n",
    "    다음은 고양이의 키포인트 데이터입니다. 이 데이터를 바탕으로 고양이의 행동을 분석해주세요. \n",
    "\n",
    "    {keypoints_str}\n",
    "\n",
    "    이 데이터를 바탕으로 고양이의 행동을 분석해주세요. \n",
    "    다음 사항들을 고려하여 분석해 주세요:\n",
    "    1. 고양이의 자세\n",
    "    2. 움직임의 패턴\n",
    "    3. 머리, 등, 꼬리의 위치\n",
    "    4. 시간에 따른 키포인트의 변화\n",
    "\n",
    "    분석 결과에는 다음 내용을 포함해 주세요:\n",
    "    1. 고양이가 취하고 있는 주요 행동\n",
    "    2. 고양이의 감정 상태 추정\n",
    "    3. 고통이나 질병의 징후가 있는지 여부\n",
    "    4. 비정상적인 행동이 있는지 여부\n",
    "\n",
    "    핵심만 짧게 요약해주세요.\n",
    "    출력은 아래 형태로 제공해주세요.\n",
    "    [품종]:[품종 추정, 모르면 '알수없음'],\n",
    "    [행동]:[주요 행동을 한 문장으로 설명],\n",
    "    [감정]:[고양이의 감정 상태를 한 문장으로 설명],\n",
    "    [질병/통증]:[질병이나 통증이 있는지 여부를 한 문장으로 설명],\n",
    "    [비정상행동]:[비정상적인 행동이 있는지 여부를 한 문장으로 설명]\n",
    "    \"\"\"\n",
    "\n",
    "    # LLM API 호출  \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"당신은 동물 행동 분석 전문가입니다. 키포인트 데이터를 바탕으로 고양이의 행동을 분석하고 감정 상태, 질병과 통증여부, 비정상 행동 여부를 체크할 수 있습니다.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=1000\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def compare_analysis_with_metadata(analysis_result, json_data):\n",
    "    print(\"LLM 분석 결과:\")\n",
    "    print(analysis_result)\n",
    "    print(\"\\n실제 메타데이터:\")\n",
    "    \n",
    "    metadata = json_data.get('metadata', {})\n",
    "    if metadata:\n",
    "        print(json.dumps(metadata, indent=2, ensure_ascii=False))\n",
    "    else:\n",
    "        print(\"메타데이터를 찾을 수 없습니다.\")\n",
    "    \n",
    "    print(\"\\n비교 분석:\")\n",
    "    # LLM 분석 결과와 메타데이터 비교\n",
    "    if metadata:\n",
    "        inspect = metadata.get('inspect', {})\n",
    "        print(f\"실제 행동: {inspect.get('action', '정보 없음')}\")\n",
    "        print(f\"실제 감정: {inspect.get('emotion', '정보 없음')}\")\n",
    "        print(f\"통증/질병 여부: {inspect.get('painDisease', '정보 없음')}\")\n",
    "        print(f\"비정상 행동 여부: {inspect.get('abnormalAction', '정보 없음')}\")\n",
    "        \n",
    "        # 여기에 LLM 분석 결과와 메타데이터를 비교하는 추가 로직을 구현할 수 있습니다.\n",
    "    else:\n",
    "        print(\"메타데이터가 없어 비교 분석을 수행할 수 없습니다.\")\n",
    "\n",
    "# JSON 파일 로드 및 분석 실행 부분\n",
    "with open('E:/LSTN_test/data/ARCH/20201028_cat-arch-000156.mp4.json', 'r', encoding='utf-8') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "analysis_result = analyze_keypoints_with_llm(json_data)\n",
    "\n",
    "# 분석 결과와 메타데이터 비교\n",
    "compare_analysis_with_metadata(analysis_result, json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from openai import OpenAI\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "yolo_model = YOLO(\"E:/1006/model/yolo_model.pt\")\n",
    "conf_thresh = 0.7\n",
    "\n",
    "def process_yolo_keypoints(results):\n",
    "    keypoints_sequence = []\n",
    "    for r in results:\n",
    "        if r.keypoints is not None:\n",
    "            frame_keypoints = r.keypoints.xy[0].cpu().numpy().tolist()\n",
    "            keypoints_sequence.append(frame_keypoints)\n",
    "    return keypoints_sequence\n",
    "\n",
    "def analyze_keypoints_with_llm(keypoints_sequence):\n",
    "    keypoints_str = json.dumps(keypoints_sequence, indent=2)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    다음은 개의 키포인트 데이터 시퀀스입니다. 각 프레임마다 24개의 키포인트가 있으며, 순서는 다음과 같습니다:\n",
    "    0: Front Left Paw, 1: Front Left Knee, 2: Front Left Elbow, 3: Rear Left Paw, 4: Rear Left Knee,\n",
    "    5: Rear Left Elbow, 6: Front Right Paw, 7: Front Right Knee, 8: Front Right Elbow, 9: Rear Right Paw,\n",
    "    10: Rear Right Knee, 11: Rear Right Elbow, 12: Tail Start, 13: Tail End, 14: Left Ear Base,\n",
    "    15: Right Ear Base, 16: Nose, 17: Chin, 18: Left Ear Tip, 19: Right Ear Tip, 20: Left Eye,\n",
    "    21: Right Eye, 22: Withers, 23: Throat\n",
    "\n",
    "    키포인트 데이터:\n",
    "    {keypoints_str}\n",
    "\n",
    "    이 데이터를 바탕으로 개의 행동을 분석해주세요. 다음 사항들을 고려하여 분석해 주세요:\n",
    "    1. 개의 자세와 움직임 패턴\n",
    "    2. 머리, 꼬리, 귀의 위치와 움직임\n",
    "    3. 시간에 따른 키포인트의 변화\n",
    "\n",
    "    분석 결과에는 다음 내용을 포함해 주세요:\n",
    "    1. 개가 취하고 있는 주요 행동\n",
    "    2. 개의 감정 상태 추정\n",
    "    3. 고통이나 질병의 징후가 있는지 여부\n",
    "    4. 비정상적인 행동이 있는지 여부\n",
    "\n",
    "    출력은 아래 형태로 제공해주세요:\n",
    "    [행동]:[주요 행동을 한 문장으로 설명],\n",
    "    [감정]:[개의 감정 상태를 한 문장으로 설명],\n",
    "    [질병/통증]:[질병이나 통증이 있는지 여부를 한 문장으로 설명],\n",
    "    [비정상행동]:[비정상적인 행동이 있는지 여부를 한 문장으로 설명]\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"당신은 동물 행동 분석 전문가입니다. 키포인트 데이터를 바탕으로 개의 행동을 정확하게 분석할 수 있습니다.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=1000\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def analyze_video():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Video files\", \"*.mp4;*.avi;*.mov\")])\n",
    "    if file_path:\n",
    "        # YOLO 모델 예측 및 키포인트 추출\n",
    "        results = yolo_model.predict(source=file_path, save=False, conf=conf_thresh, stream=True, verbose=False)\n",
    "        keypoints_sequence = process_yolo_keypoints(results)\n",
    "\n",
    "        # LLM 분석\n",
    "        llm_analysis = analyze_keypoints_with_llm(keypoints_sequence)\n",
    "        \n",
    "        # 결과 표시\n",
    "        result_window = tk.Toplevel(root)\n",
    "        result_window.title(\"분석 결과\")\n",
    "        result_text = tk.Text(result_window, wrap=tk.WORD, width=60, height=20)\n",
    "        result_text.insert(tk.END, llm_analysis)\n",
    "        result_text.pack(padx=10, pady=10)\n",
    "\n",
    "# GUI 생성\n",
    "root = tk.Tk()\n",
    "root.title(\"개 행동 분석기\")\n",
    "\n",
    "upload_button = tk.Button(root, text=\"비디오 업로드 및 분석\", command=analyze_video)\n",
    "upload_button.pack(pady=20)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# 비디오 폴더와 모범 답안 파일 경로 설정\n",
    "VIDEO_FOLDER = \"E:/dog_videos/\"\n",
    "GROUND_TRUTH_FILE = \"E:/dog_videos/ground_truth.json\"\n",
    "\n",
    "def load_ground_truth():\n",
    "    with open(GROUND_TRUTH_FILE, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def evaluate_results(ground_truth, echo_result, gpt4o_result):\n",
    "    # BLEU 점수 계산\n",
    "    reference = nltk.word_tokenize(ground_truth.lower())\n",
    "    echo_bleu = sentence_bleu([reference], nltk.word_tokenize(echo_result.lower()))\n",
    "    gpt4o_bleu = sentence_bleu([reference], nltk.word_tokenize(gpt4o_result.lower()))\n",
    "\n",
    "    # 간단한 키워드 기반 정확도 계산\n",
    "    keywords = set(ground_truth.lower().split())\n",
    "    echo_accuracy = len(set(echo_result.lower().split()) & keywords) / len(keywords)\n",
    "    gpt4o_accuracy = len(set(gpt4o_result.lower().split()) & keywords) / len(keywords)\n",
    "\n",
    "    return {\n",
    "        \"echo_bleu\": echo_bleu,\n",
    "        \"gpt4o_bleu\": gpt4o_bleu,\n",
    "        \"echo_accuracy\": echo_accuracy,\n",
    "        \"gpt4o_accuracy\": gpt4o_accuracy\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    ground_truths = load_ground_truth()\n",
    "    results = []\n",
    "\n",
    "    for video_file in os.listdir(VIDEO_FOLDER):\n",
    "        if video_file.endswith(('.mp4', '.avi', '.mov')):  # 비디오 파일 확장자\n",
    "            video_path = os.path.join(VIDEO_FOLDER, video_file)\n",
    "            print(f\"처리 중인 비디오: {video_file}\")\n",
    "\n",
    "            # 기존의 분석 코드 (YOLO, LSTM, LLM 등)\n",
    "            # ...\n",
    "\n",
    "            # Echo Demo 분석 결과\n",
    "            echo_result = generate_comprehensive_analysis(yolo_text, lstm_text, summary_text, rag_text)\n",
    "\n",
    "            # GPT-4o-mini 분석 결과\n",
    "            gpt4o_prompt = f\"\"\"\n",
    "            강아지 영상 분석 결과:\n",
    "            1. YOLO 모델 (품종 탐지): {yolo_text}\n",
    "            2. LSTM 모델 (행동 분석): {lstm_text}\n",
    "            3. 비디오 요약: {summary_text}\n",
    "\n",
    "            위 정보를 바탕으로 강아지의 상태, 행동, 감정에 대해 종합적으로 분석해주세요.\n",
    "            \"\"\"\n",
    "            gpt4o_response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini-2024-07-18\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"당신은 강아지 행동 분석 전문가입니다.\"},\n",
    "                    {\"role\": \"user\", \"content\": gpt4o_prompt}\n",
    "                ],\n",
    "                max_tokens=150\n",
    "            )\n",
    "            gpt4o_result = gpt4o_response.choices[0].message.content\n",
    "\n",
    "            # 결과 평가\n",
    "            ground_truth = ground_truths.get(video_file, \"\")\n",
    "            evaluation = evaluate_results(ground_truth, echo_result, gpt4o_result)\n",
    "            results.append({\n",
    "                \"video\": video_file,\n",
    "                \"ground_truth\": ground_truth,\n",
    "                \"echo_result\": echo_result,\n",
    "                \"gpt4o_result\": gpt4o_result,\n",
    "                \"evaluation\": evaluation\n",
    "            })\n",
    "\n",
    "            print(f\"비디오 {video_file} 처리 완료\")\n",
    "            print(\"평가 결과:\", evaluation)\n",
    "            print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    # 전체 결과 요약\n",
    "    avg_echo_bleu = sum(r['evaluation']['echo_bleu'] for r in results) / len(results)\n",
    "    avg_gpt4o_bleu = sum(r['evaluation']['gpt4o_bleu'] for r in results) / len(results)\n",
    "    avg_echo_accuracy = sum(r['evaluation']['echo_accuracy'] for r in results) / len(results)\n",
    "    avg_gpt4o_accuracy = sum(r['evaluation']['gpt4o_accuracy'] for r in results) / len(results)\n",
    "\n",
    "    print(\"=== 전체 평가 결과 ===\")\n",
    "    print(f\"Echo Demo 평균 BLEU 점수: {avg_echo_bleu:.4f}\")\n",
    "    print(f\"GPT-4o-mini 평균 BLEU 점수: {avg_gpt4o_bleu:.4f}\")\n",
    "    print(f\"Echo Demo 평균 정확도: {avg_echo_accuracy:.4f}\")\n",
    "    print(f\"GPT-4o-mini 평균 정확도: {avg_gpt4o_accuracy:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
