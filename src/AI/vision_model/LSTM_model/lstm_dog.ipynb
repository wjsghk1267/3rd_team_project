{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 244\u001b[0m\n\u001b[0;32m    241\u001b[0m val_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:/LSTN_test/json/Validation/DOG\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 244\u001b[0m     train_keypoints, train_skeleton, train_labels, train_metadata, train_class_names \u001b[38;5;241m=\u001b[39m \u001b[43mload_json_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m     val_keypoints, val_skeleton, val_labels, val_metadata, val_class_names \u001b[38;5;241m=\u001b[39m load_json_files(val_folder)\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;66;03m# 클래스 이름 통합\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 114\u001b[0m, in \u001b[0;36mload_json_files\u001b[1;34m(folder_path)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         json_data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m         keypoints_sequence \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    116\u001b[0m         skeleton_sequence \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\ca_da\\anaconda\\Lib\\json\\__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[0;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[0;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[0;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m<frozen codecs>:319\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# device 정의\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "DOG_SKELETON = [\n",
    "    [0, 1],  # 코에서 이마\n",
    "    [0, 2],  # 코에서 입꼬리\n",
    "    [2, 3],  # 입꼬리에서 아랫입술\n",
    "    [1, 4],  # 이마에서 목\n",
    "    [4, 5],  # 목에서 오른쪽 앞다리 시작점\n",
    "    [4, 6],  # 목에서 왼쪽 앞다리 시작점\n",
    "    [5, 7],  # 오른쪽 앞다리 시작점에서 오른쪽 앞발목\n",
    "    [6, 8],  # 왼쪽 앞다리 시작점에서 왼쪽 앞발목\n",
    "    [9, 11],  # 오른쪽 허벅지에서 오른쪽 뒷발목\n",
    "    [10, 12],  # 왼쪽 허벅지에서 왼쪽 뒷발목\n",
    "    [4, 13],  # 목에서 꼬리 시작점\n",
    "    [13, 14],  # 꼬리 시작점에서 꼬리 끝\n",
    "    [9, 13],  # 오른쪽 허벅지에서 꼬리 시작점 (오른쪽 하체)\n",
    "    [10, 13], # 왼쪽 허벅지에서 꼬리 시작점 (왼쪽 하체)\n",
    "    [5, 9],   # 오른쪽 앞다리 시작점에서 오른쪽 허벅지 (오른쪽 몸통)\n",
    "    [6, 10],  # 왼쪽 앞다리 시작점에서 왼쪽 허벅지 (왼쪽 몸통)\n",
    "    [5, 6],   # 오른쪽 앞다리 시작점에서 왼쪽 앞다리 시작점 (가슴 윤곽)\n",
    "    [9, 10]   # 오른쪽 허벅지에서 왼쪽 허벅지 (엉덩이 윤곽)\n",
    "]\n",
    "\n",
    "def extract_keypoints(keypoints):\n",
    "    extracted = []\n",
    "    for i in range(1, 16):  # 1부터 15까지의 키포인트\n",
    "        point = keypoints.get(str(i))\n",
    "        if point is not None:\n",
    "            extracted.extend([point['x'], point['y']])\n",
    "        else:\n",
    "            extracted.extend([0, 0])  # 없는 키포인트는 (0, 0)으로 처리\n",
    "    return extracted\n",
    "\n",
    "def extract_skeleton(keypoints):\n",
    "    skeleton = []\n",
    "    for start, end in DOG_SKELETON:\n",
    "        start_point = keypoints.get(str(start+1))\n",
    "        end_point = keypoints.get(str(end+1))\n",
    "        if start_point and end_point:\n",
    "            skeleton.extend([start_point['x'], start_point['y'], end_point['x'], end_point['y']])\n",
    "        else:\n",
    "            skeleton.extend([0, 0, 0, 0])\n",
    "    return skeleton\n",
    "\n",
    "def standardize_sequence_length(sequence, target_length=100):\n",
    "    current_length = len(sequence)\n",
    "    if current_length > target_length:\n",
    "        indices = np.linspace(0, current_length-1, target_length, dtype=int)\n",
    "        return [sequence[i] for i in indices]\n",
    "    elif current_length < target_length:\n",
    "        padding = [sequence[-1]] * (target_length - current_length)\n",
    "        return sequence + padding\n",
    "    else:\n",
    "        return sequence\n",
    "\n",
    "def temporal_augmentation(sequence, max_skip=2):\n",
    "    augmented = []\n",
    "    i = 0\n",
    "    while i < len(sequence):\n",
    "        augmented.append(sequence[i])\n",
    "        i += random.randint(1, max_skip)\n",
    "    return augmented\n",
    "\n",
    "def reverse_sequence(sequence):\n",
    "    return sequence[::-1]\n",
    "\n",
    "def add_temporal_noise(sequence, noise_level=0.05):\n",
    "    noisy_sequence = []\n",
    "    for frame in sequence:\n",
    "        noisy_frame = np.array(frame) + np.random.normal(0, noise_level, len(frame))\n",
    "        noisy_sequence.append(noisy_frame.tolist())\n",
    "    return noisy_sequence\n",
    "\n",
    "def get_sequence_weight(sequence_length, max_length=100):\n",
    "    return min(sequence_length / max_length, 1.0)\n",
    "\n",
    "def load_json_files(folder_path):\n",
    "    keypoints_data = []\n",
    "    skeleton_data = []\n",
    "    labels = []\n",
    "    metadata = []\n",
    "    total_files = 0\n",
    "    processed_files = 0\n",
    "    skipped_files = 0\n",
    "    class_names = []\n",
    "    \n",
    "    for action_folder in os.listdir(folder_path):\n",
    "        action_path = os.path.join(folder_path, action_folder)\n",
    "        if os.path.isdir(action_path):\n",
    "            class_name = action_folder.upper()\n",
    "            if class_name not in class_names:\n",
    "                class_names.append(class_name)\n",
    "            class_index = class_names.index(class_name)\n",
    "            \n",
    "            for filename in os.listdir(action_path):\n",
    "                if filename.endswith('.json'):\n",
    "                    total_files += 1\n",
    "                    file_path = os.path.join(action_path, filename)\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        try:\n",
    "                            json_data = json.load(f)\n",
    "                            keypoints_sequence = []\n",
    "                            skeleton_sequence = []\n",
    "                            for annotation in json_data['annotations']:\n",
    "                                keypoints = extract_keypoints(annotation['keypoints'])\n",
    "                                skeleton = extract_skeleton(annotation['keypoints'])\n",
    "                                if keypoints and skeleton:\n",
    "                                    keypoints_sequence.append(keypoints)\n",
    "                                    skeleton_sequence.append(skeleton)\n",
    "                            \n",
    "                            if keypoints_sequence and skeleton_sequence:\n",
    "                                # 시퀀스 길이 표준화\n",
    "                                keypoints_sequence = standardize_sequence_length(keypoints_sequence)\n",
    "                                skeleton_sequence = standardize_sequence_length(skeleton_sequence)\n",
    "                                \n",
    "                                # 데이터 증강 (50% 확률로 적용)\n",
    "                                if random.random() < 0.5:\n",
    "                                    keypoints_sequence = temporal_augmentation(keypoints_sequence)\n",
    "                                    skeleton_sequence = temporal_augmentation(skeleton_sequence)\n",
    "                                \n",
    "                                if random.random() < 0.5:\n",
    "                                    keypoints_sequence = reverse_sequence(keypoints_sequence)\n",
    "                                    skeleton_sequence = reverse_sequence(skeleton_sequence)\n",
    "                                \n",
    "                                if random.random() < 0.5:\n",
    "                                    keypoints_sequence = add_temporal_noise(keypoints_sequence)\n",
    "                                    skeleton_sequence = add_temporal_noise(skeleton_sequence)\n",
    "                                \n",
    "                                # 시퀀스 길이에 따른 가중치 계산\n",
    "                                weight = get_sequence_weight(len(keypoints_sequence))\n",
    "                                \n",
    "                                keypoints_data.append(keypoints_sequence)\n",
    "                                skeleton_data.append(skeleton_sequence)\n",
    "                                labels.append(class_index)\n",
    "                                metadata.append({\n",
    "                                    'pain': json_data['metadata']['owner']['pain'],\n",
    "                                    'disease': json_data['metadata']['owner']['disease'],\n",
    "                                    'emotion': json_data['metadata']['owner']['emotion'],\n",
    "                                    'abnormal_action': json_data['metadata']['inspect']['abnormalAction'],\n",
    "                                    'weight': weight  # 가중치 추가\n",
    "                                })\n",
    "                                processed_files += 1\n",
    "                            else:\n",
    "                                print(f\"경고: {filename}에서 유효한 시퀀스를 추출하지 못했습니다.\")\n",
    "                                skipped_files += 1\n",
    "                        except Exception as e:\n",
    "                            print(f\"오류 발생: {filename} 처리 중 {str(e)}\")\n",
    "                            skipped_files += 1\n",
    "    \n",
    "    print(f\"총 파일 수: {total_files}\")\n",
    "    print(f\"처리된 파일 수: {processed_files}\")\n",
    "    print(f\"건너뛴 파일 수: {skipped_files}\")\n",
    "    print(f\"클래스 목록: {class_names}\")\n",
    "    \n",
    "    if not keypoints_data:\n",
    "        raise ValueError(\"로드된 데이터가 없습니다. 데이터 경로와 파일을 확인하세요.\")\n",
    "    \n",
    "    return keypoints_data, skeleton_data, labels, metadata, class_names\n",
    "\n",
    "class ImprovedLSTMModel(nn.Module):\n",
    "    def __init__(self, keypoint_size, skeleton_size, hidden_size, num_layers, num_classes):\n",
    "        super(ImprovedLSTMModel, self).__init__()\n",
    "        self.keypoint_lstm = nn.LSTM(keypoint_size, hidden_size, num_layers, batch_first=True, dropout=0.5)\n",
    "        self.skeleton_lstm = nn.LSTM(skeleton_size, hidden_size, num_layers, batch_first=True, dropout=0.5)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, keypoints, skeleton):\n",
    "        _, (h_n_keypoints, _) = self.keypoint_lstm(keypoints)\n",
    "        _, (h_n_skeleton, _) = self.skeleton_lstm(skeleton)\n",
    "        \n",
    "        combined = torch.cat((h_n_keypoints[-1], h_n_skeleton[-1]), dim=1)\n",
    "        out = self.dropout(combined)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "def save_model(epoch, model, optimizer, scheduler, train_loss, val_loss, filename, all_class_names):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'keypoint_size': model.keypoint_lstm.input_size,\n",
    "        'skeleton_size': model.skeleton_lstm.input_size,\n",
    "        'hidden_size': model.keypoint_lstm.hidden_size,\n",
    "        'num_layers': model.keypoint_lstm.num_layers,\n",
    "        'num_classes': model.fc.out_features,\n",
    "        'all_class_names': all_class_names\n",
    "    }, filename)\n",
    "\n",
    "# 데이터 로드\n",
    "train_folder = 'E:/LSTN_test/json/Training/DOG'\n",
    "val_folder = 'E:/LSTN_test/json/Validation/DOG'\n",
    "\n",
    "try:\n",
    "    train_keypoints, train_skeleton, train_labels, train_metadata, train_class_names = load_json_files(train_folder)\n",
    "    val_keypoints, val_skeleton, val_labels, val_metadata, val_class_names = load_json_files(val_folder)\n",
    "    \n",
    "    # 클래스 이름 통합\n",
    "    all_class_names = list(set(train_class_names + val_class_names))\n",
    "except ValueError as e:\n",
    "    print(f\"오류: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "def pad_sequences(sequences, max_length=None, padding_value=0.0):\n",
    "    if max_length is None:\n",
    "        max_length = max(len(seq) for seq in sequences)\n",
    "    \n",
    "    padded_sequences = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) > max_length:\n",
    "            padded_sequences.append(seq[:max_length])\n",
    "        else:\n",
    "            padding = [[padding_value] * len(seq[0])] * (max_length - len(seq))\n",
    "            padded_sequences.append(seq + padding)\n",
    "    return padded_sequences\n",
    "\n",
    "keypoints_data = pad_sequences(keypoints_data)\n",
    "skeleton_data = pad_sequences(skeleton_data)\n",
    "\n",
    "# 데이터 로딩 후, 텐서로 변환하기 전에 패딩 적용\n",
    "max_length = max(\n",
    "    max(len(seq) for seq in train_keypoints),\n",
    "    max(len(seq) for seq in train_skeleton),\n",
    "    max(len(seq) for seq in val_keypoints),\n",
    "    max(len(seq) for seq in val_skeleton)\n",
    ")\n",
    "\n",
    "print(f\"Max sequence length: {max_length}\")\n",
    "\n",
    "# Keypoints와 Skeleton 데이터의 shape 확인\n",
    "print(f\"Train keypoints shape before padding: {np.array(train_keypoints).shape}\")\n",
    "print(f\"Train skeleton shape before padding: {np.array(train_skeleton).shape}\")\n",
    "\n",
    "train_keypoints = pad_sequences(train_keypoints, max_length)\n",
    "train_skeleton = pad_sequences(train_skeleton, max_length)\n",
    "val_keypoints = pad_sequences(val_keypoints, max_length)\n",
    "val_skeleton = pad_sequences(val_skeleton, max_length)\n",
    "\n",
    "print(f\"Train keypoints shape after padding: {train_keypoints.shape}\")\n",
    "print(f\"Train skeleton shape after padding: {train_skeleton.shape}\")\n",
    "\n",
    "# 텐서로 변환\n",
    "X_train_keypoints = torch.FloatTensor(train_keypoints)\n",
    "X_train_skeleton = torch.FloatTensor(train_skeleton)\n",
    "y_train = torch.LongTensor(train_labels)\n",
    "X_val_keypoints = torch.FloatTensor(val_keypoints)\n",
    "X_val_skeleton = torch.FloatTensor(val_skeleton)\n",
    "y_val = torch.LongTensor(val_labels)\n",
    "\n",
    "print(f\"Final tensor shapes:\")\n",
    "print(f\"X_train_keypoints: {X_train_keypoints.shape}\")\n",
    "print(f\"X_train_skeleton: {X_train_skeleton.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "\n",
    "# 데이터로더 생성\n",
    "train_dataset = TensorDataset(X_train_keypoints, X_train_skeleton, y_train, torch.tensor(train_metadata))\n",
    "val_dataset = TensorDataset(X_val_keypoints, X_val_skeleton, y_val, torch.tensor(val_metadata))\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 모델 파라미터\n",
    "keypoint_size = X_train_keypoints.shape[2]\n",
    "skeleton_size = X_train_skeleton.shape[2]\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = len(all_class_names)\n",
    "\n",
    "# 저장된 모델 확인 및 로드\n",
    "latest_checkpoint = max([f for f in os.listdir('.') if f.startswith('improved_lstm_model_dog_epoch_')], default=None)\n",
    "start_epoch = 0\n",
    "\n",
    "if latest_checkpoint:\n",
    "    print(f\"최신 체크포인트 발견: {latest_checkpoint}\")\n",
    "    checkpoint = torch.load(latest_checkpoint, map_location=device)\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    \n",
    "    keypoint_size = checkpoint['keypoint_size']\n",
    "    skeleton_size = checkpoint['skeleton_size']\n",
    "    hidden_size = checkpoint['hidden_size']\n",
    "    num_layers = checkpoint['num_layers']\n",
    "    num_classes = checkpoint['num_classes']\n",
    "    all_class_names = checkpoint['all_class_names']\n",
    "    \n",
    "    model = ImprovedLSTMModel(keypoint_size, skeleton_size, hidden_size, num_layers, num_classes).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.1)\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "    print(f\"체크포인트에서 학습 재개: 에포크 {start_epoch}\")\n",
    "else:\n",
    "    print(\"새로운 학습 시작\")\n",
    "    model = ImprovedLSTMModel(keypoint_size, skeleton_size, hidden_size, num_layers, num_classes).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.1)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "# 학습\n",
    "num_epochs = 100\n",
    "patience = 20\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True, path='best_model.pt')\n",
    "\n",
    "for epoch in tqdm(range(start_epoch, num_epochs), desc=\"Epochs\"):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_keypoints, batch_skeleton, batch_y, batch_meta in train_loader:\n",
    "        batch_keypoints, batch_skeleton, batch_y = batch_keypoints.to(device), batch_skeleton.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_keypoints, batch_skeleton)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        weights = torch.tensor([meta['weight'] for meta in batch_meta]).to(device)\n",
    "        weighted_loss = (loss * weights).mean()\n",
    "        weighted_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += weighted_loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    train_loss = total_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "    \n",
    "    # 검증\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_keypoints, batch_skeleton, batch_y, batch_meta in val_loader:\n",
    "            batch_keypoints, batch_skeleton, batch_y = batch_keypoints.to(device), batch_skeleton.to(device), batch_y.to(device)\n",
    "            outputs = model(batch_keypoints, batch_skeleton)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            weights = torch.tensor([meta['weight'] for meta in batch_meta]).to(device)\n",
    "            weighted_loss = (loss * weights).mean()\n",
    "            val_loss += weighted_loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += batch_y.size(0)\n",
    "            val_correct += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    \n",
    "    print(f'에포크 [{epoch+1}/{num_epochs}], 학습 손실: {train_loss:.4f}, 학습 정확도: {train_accuracy:.2f}%, 검증 손실: {val_loss:.4f}, 검증 정확도: {val_accuracy:.2f}%')\n",
    "    \n",
    "    # 10 에포크마다 모델 저장\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        save_model(epoch, model, optimizer, scheduler, train_loss, val_loss, f'improved_lstm_model_dog_epoch_{epoch+1}.pt', all_class_names)\n",
    "    \n",
    "    # Early Stopping 체크\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "print(\"학습 완료\")\n",
    "\n",
    "# 최종 모델 저장\n",
    "save_model(epoch, model, optimizer, scheduler, train_loss, val_loss, 'improved_lstm_model_dog_final.pt', all_class_names)\n",
    "\n",
    "# 최상의 모델 로드\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "\n",
    "# 전체 데이터셋에 대한 평가\n",
    "full_dataset = ConcatDataset([train_dataset, val_dataset])\n",
    "full_loader = DataLoader(full_dataset, batch_size=32, shuffle=False)\n",
    "all_meta = train_metadata + val_metadata\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "all_predictions = []\n",
    "all_true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_keypoints, batch_skeleton, batch_y, _ in full_loader:\n",
    "        batch_keypoints, batch_skeleton, batch_y = batch_keypoints.to(device), batch_skeleton.to(device), batch_y.to(device)\n",
    "        outputs = model(batch_keypoints, batch_skeleton)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (predicted == batch_y).sum().item()\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_true_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "print(f'전체 데이터셋 정확도: {100 * correct / total:.2f}%')\n",
    "\n",
    "# 예측 결과와 메타데이터 함께 표시\n",
    "for i, (pred, true) in enumerate(zip(all_predictions, all_true_labels)):\n",
    "    pred_class = all_class_names[pred]\n",
    "    true_class = all_class_names[true]\n",
    "    print(f\"샘플 {i+1}:\")\n",
    "    print(f\"  예측: {pred_class}, 실제: {true_class}\")\n",
    "    print(f\"  메타데이터:\")\n",
    "    print(f\"    통증: {all_meta[i]['pain']}\")\n",
    "    print(f\"    질병: {all_meta[i]['disease']}\")\n",
    "    print(f\"    감정: {all_meta[i]['emotion']}\")\n",
    "    print(f\"    비정상 행동: {all_meta[i]['abnormal_action']}\")\n",
    "    print()\n",
    "\n",
    "print(\"최종 모델이 'improved_lstm_model_dog_final.pt'로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\administrator\\appdata\\local\\programs\\python\\python312\\lib\\site-packages\\torchlight-1.0-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 파일 수: 39537\n",
      "처리된 파일 수: 39537\n",
      "건너뛴 파일 수: 0\n",
      "클래스 목록: ['BODYLOWER', 'BODYSCRATCH', 'BODYSHAKE', 'FEETUP', 'FOOTUP', 'HEADING', 'LYING', 'MOUNTING', 'SIT', 'TAILING', 'TAILLOW', 'TURN', 'WALKRUN']\n",
      "총 파일 수: 4949\n",
      "처리된 파일 수: 4949\n",
      "건너뛴 파일 수: 0\n",
      "클래스 목록: ['BODYLOWER', 'BODYSCRATCH', 'BODYSHAKE', 'FEETUP', 'FOOTUP', 'HEADING', 'LYING', 'MOUNTING', 'SIT', 'TAILING', 'TAILLOW', 'TURN', 'WALKRUN']\n",
      "train_keypoints shape: (39537, 100, 30)\n",
      "train_skeleton shape: (39537, 100, 72)\n",
      "새 모델로 훈련을 시작합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 337\u001b[0m\n\u001b[0;32m    334\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;66;03m# 훈련 루프\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, \u001b[43mnum_epochs\u001b[49m):\n\u001b[0;32m    338\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    339\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_epochs' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, ConcatDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 강아지 골격 정의\n",
    "DOG_SKELETON = [\n",
    "    [0, 1], [0, 2], [2, 3], [1, 4], [4, 5], [4, 6], [5, 7], [6, 8],\n",
    "    [9, 11], [10, 12], [4, 13], [13, 14], [9, 13], [10, 13], [5, 9],\n",
    "    [6, 10], [5, 6], [9, 10]\n",
    "]\n",
    "\n",
    "def extract_keypoints(keypoints):\n",
    "    extracted = []\n",
    "    for i in range(1, 16):\n",
    "        point = keypoints.get(str(i))\n",
    "        if point is not None:\n",
    "            extracted.extend([point['x'], point['y']])\n",
    "        else:\n",
    "            extracted.extend([float('nan'), float('nan')])  # 누락된 키포인트를 NaN으로 처리\n",
    "    return extracted\n",
    "\n",
    "def extract_skeleton(keypoints):\n",
    "    skeleton = []\n",
    "    for start, end in DOG_SKELETON:\n",
    "        start_point = keypoints.get(str(start+1))\n",
    "        end_point = keypoints.get(str(end+1))\n",
    "        if start_point and end_point:\n",
    "            skeleton.extend([start_point['x'], start_point['y'], end_point['x'], end_point['y']])\n",
    "        else:\n",
    "            skeleton.extend([float('nan'), float('nan'), float('nan'), float('nan')])  # 누락된 골격 정보를 NaN으로 처리\n",
    "    return skeleton\n",
    "\n",
    "def standardize_sequence_length(sequence, target_length=100):\n",
    "    current_length = len(sequence)\n",
    "    if current_length > target_length:\n",
    "        indices = np.linspace(0, current_length-1, target_length, dtype=int)\n",
    "        return [sequence[i] for i in indices]\n",
    "    elif current_length < target_length:\n",
    "        padding = [sequence[-1]] * (target_length - current_length)\n",
    "        return sequence + padding\n",
    "    else:\n",
    "        return sequence\n",
    "\n",
    "def temporal_augmentation(sequence, max_skip=2):\n",
    "    augmented = []\n",
    "    i = 0\n",
    "    while i < len(sequence):\n",
    "        augmented.append(sequence[i])\n",
    "        i += random.randint(1, max_skip)\n",
    "    return augmented\n",
    "\n",
    "def reverse_sequence(sequence):\n",
    "    return sequence[::-1]\n",
    "\n",
    "def add_temporal_noise(sequence, noise_level=0.05):\n",
    "    noisy_sequence = []\n",
    "    for frame in sequence:\n",
    "        noisy_frame = np.array(frame) + np.random.normal(0, noise_level, len(frame))\n",
    "        noisy_sequence.append(noisy_frame.tolist())\n",
    "    return noisy_sequence\n",
    "\n",
    "def get_sequence_weight(sequence_length, max_length=100):\n",
    "    return min(sequence_length / max_length, 1.0)\n",
    "\n",
    "def pad_sequences(sequences, max_length=None, padding_value=0.0):\n",
    "    if max_length is None:\n",
    "        max_length = max(len(seq) for seq in sequences)\n",
    "    \n",
    "    padded_sequences = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) > max_length:\n",
    "            padded_sequences.append(seq[:max_length])\n",
    "        else:\n",
    "            padding = [[padding_value] * len(seq[0])] * (max_length - len(seq))\n",
    "            padded_sequences.append(seq + padding)\n",
    "    return padded_sequences\n",
    "\n",
    "def load_json_files(folder_path):\n",
    "    keypoints_data = []\n",
    "    skeleton_data = []\n",
    "    labels = []\n",
    "    metadata = []\n",
    "    total_files = 0\n",
    "    processed_files = 0\n",
    "    skipped_files = 0\n",
    "    class_names = []\n",
    "    \n",
    "    for action_folder in os.listdir(folder_path):\n",
    "        action_path = os.path.join(folder_path, action_folder)\n",
    "        if os.path.isdir(action_path):\n",
    "            class_name = action_folder.upper()\n",
    "            if class_name not in class_names:\n",
    "                class_names.append(class_name)\n",
    "            class_index = class_names.index(class_name)\n",
    "            \n",
    "            for filename in os.listdir(action_path):\n",
    "                if filename.endswith('.json'):\n",
    "                    total_files += 1\n",
    "                    file_path = os.path.join(action_path, filename)\n",
    "                    try:\n",
    "                        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                            json_data = json.load(f)\n",
    "                            keypoints_sequence = []\n",
    "                            skeleton_sequence = []\n",
    "                            for annotation in json_data['annotations']:\n",
    "                                keypoints = extract_keypoints(annotation['keypoints'])\n",
    "                                skeleton = extract_skeleton(annotation['keypoints'])\n",
    "                                if keypoints and skeleton:\n",
    "                                    keypoints_sequence.append(keypoints)\n",
    "                                    skeleton_sequence.append(skeleton)\n",
    "                            \n",
    "                            if keypoints_sequence and skeleton_sequence:\n",
    "                                # 시퀀스 길이 표준화\n",
    "                                keypoints_sequence = standardize_sequence_length(keypoints_sequence)\n",
    "                                skeleton_sequence = standardize_sequence_length(skeleton_sequence)\n",
    "                                \n",
    "                                # 데이터 증강 (50% 확률로 적용)\n",
    "                                if random.random() < 0.5:\n",
    "                                    keypoints_sequence = temporal_augmentation(keypoints_sequence)\n",
    "                                    skeleton_sequence = temporal_augmentation(skeleton_sequence)\n",
    "                                \n",
    "                                if random.random() < 0.5:\n",
    "                                    keypoints_sequence = reverse_sequence(keypoints_sequence)\n",
    "                                    skeleton_sequence = reverse_sequence(skeleton_sequence)\n",
    "                                \n",
    "                                if random.random() < 0.5:\n",
    "                                    keypoints_sequence = add_temporal_noise(keypoints_sequence)\n",
    "                                    skeleton_sequence = add_temporal_noise(skeleton_sequence)\n",
    "                                \n",
    "                                # 시퀀스 길이에 따른 가중치 계산\n",
    "                                weight = get_sequence_weight(len(keypoints_sequence))\n",
    "                                \n",
    "                                keypoints_data.append(keypoints_sequence)\n",
    "                                skeleton_data.append(skeleton_sequence)\n",
    "                                labels.append(class_index)\n",
    "                                metadata.append({\n",
    "                                    'pain': json_data['metadata']['owner']['pain'],\n",
    "                                    'disease': json_data['metadata']['owner']['disease'],\n",
    "                                    'emotion': json_data['metadata']['owner']['emotion'],\n",
    "                                    'abnormal_action': json_data['metadata']['inspect']['abnormalAction'],\n",
    "                                    'weight': weight\n",
    "                                })\n",
    "                                processed_files += 1\n",
    "                            else:\n",
    "                                print(f\"경고: {filename}에서 유효한 시퀀스를 추출하지 못했습니다.\")\n",
    "                                skipped_files += 1\n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"JSON 디코딩 오류: {filename} - {str(e)}\")\n",
    "                        skipped_files += 1\n",
    "                    except KeyError as e:\n",
    "                        print(f\"키 오류: {filename} - {str(e)}\")\n",
    "                        skipped_files += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"예상치 못한 오류: {filename} - {str(e)}\")\n",
    "                        skipped_files += 1\n",
    "    \n",
    "    print(f\"총 파일 수: {total_files}\")\n",
    "    print(f\"처리된 파일 수: {processed_files}\")\n",
    "    print(f\"건너뛴 파일 수: {skipped_files}\")\n",
    "    print(f\"클래스 목록: {class_names}\")\n",
    "    \n",
    "    if not keypoints_data:\n",
    "        raise ValueError(\"로드된 데이터가 없습니다. 데이터 경로와 파일을 확인하세요.\")\n",
    "    \n",
    "    # 패딩 적용\n",
    "    keypoints_data = pad_sequences(keypoints_data)\n",
    "    skeleton_data = pad_sequences(skeleton_data)\n",
    "    \n",
    "    return keypoints_data, skeleton_data, labels, metadata, class_names\n",
    "\n",
    "class ImprovedLSTMModel(nn.Module):\n",
    "    def __init__(self, keypoint_size, skeleton_size, hidden_size, num_layers, num_classes, dropout_rate=0.5):\n",
    "        super(ImprovedLSTMModel, self).__init__()\n",
    "        self.keypoint_lstm = nn.LSTM(keypoint_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate)\n",
    "        self.skeleton_lstm = nn.LSTM(skeleton_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate)\n",
    "        self.attention = nn.MultiheadAttention(hidden_size * 2, num_heads=4)\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, keypoints, skeleton):\n",
    "        keypoint_out, _ = self.keypoint_lstm(keypoints)\n",
    "        skeleton_out, _ = self.skeleton_lstm(skeleton)\n",
    "        \n",
    "        combined = torch.cat((keypoint_out, skeleton_out), dim=2)\n",
    "        \n",
    "        # Apply attention mechanism\n",
    "        attn_output, _ = self.attention(combined, combined, combined)\n",
    "        \n",
    "        # Global average pooling\n",
    "        pooled = torch.mean(attn_output, dim=1)\n",
    "        \n",
    "        out = self.dropout(pooled)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "def save_model(epoch, model, optimizer, scheduler, train_loss, val_loss, filename, all_class_names):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'keypoint_size': model.keypoint_lstm.input_size,\n",
    "        'skeleton_size': model.skeleton_lstm.input_size,\n",
    "        'hidden_size': model.keypoint_lstm.hidden_size,\n",
    "        'num_layers': model.keypoint_lstm.num_layers,\n",
    "        'num_classes': model.fc.out_features,\n",
    "        'all_class_names': all_class_names\n",
    "    }, filename)\n",
    "\n",
    "# 데이터 로드\n",
    "train_folder = 'E:/LSTN_test/json/Training/DOG'\n",
    "val_folder = 'E:/LSTN_test/json/Validation/DOG'\n",
    "\n",
    "try:\n",
    "    train_keypoints, train_skeleton, train_labels, train_metadata, train_class_names = load_json_files(train_folder)\n",
    "    val_keypoints, val_skeleton, val_labels, val_metadata, val_class_names = load_json_files(val_folder)\n",
    "    \n",
    "    # 클래스 이름 통합\n",
    "    all_class_names = list(set(train_class_names + val_class_names))\n",
    "except ValueError as e:\n",
    "    print(f\"오류: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "train_labels_np = np.array(train_labels)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(train_labels_np), y=train_labels_np)\n",
    "class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "\n",
    "print(\"train_keypoints shape:\", np.array(train_keypoints).shape)\n",
    "print(\"train_skeleton shape:\", np.array(train_skeleton).shape)\n",
    "\n",
    "# 텐서로 변환\n",
    "X_train_keypoints = torch.FloatTensor(train_keypoints)\n",
    "X_train_skeleton = torch.FloatTensor(train_skeleton)\n",
    "y_train = torch.LongTensor(train_labels)\n",
    "X_val_keypoints = torch.FloatTensor(val_keypoints)\n",
    "X_val_skeleton = torch.FloatTensor(val_skeleton)\n",
    "y_val = torch.LongTensor(val_labels)\n",
    "\n",
    "# 데이터로더 생성\n",
    "train_dataset = TensorDataset(X_train_keypoints, X_train_skeleton, y_train)\n",
    "val_dataset = TensorDataset(X_val_keypoints, X_val_skeleton, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 모델 파라미터\n",
    "keypoint_size = X_train_keypoints.shape[2]\n",
    "skeleton_size = X_train_skeleton.shape[2]\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = len(all_class_names)\n",
    "\n",
    "# 저장된 모델 확인 및 로드\n",
    "latest_checkpoint = max([f for f in os.listdir('.') if f.startswith('improved_lstm_model_dog_epoch_')], default=None)\n",
    "start_epoch = 0\n",
    "\n",
    "if latest_checkpoint:\n",
    "    print(f\"최신 체크포인트 발견: {latest_checkpoint}\")\n",
    "    checkpoint = torch.load(latest_checkpoint, map_location=device)\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    \n",
    "    keypoint_size = checkpoint['keypoint_size']\n",
    "    skeleton_size = checkpoint['skeleton_size']\n",
    "    hidden_size = checkpoint['hidden_size']\n",
    "    num_layers = checkpoint['num_layers']\n",
    "    num_classes = checkpoint['num_classes']\n",
    "    all_class_names = checkpoint['all_class_names']\n",
    "    \n",
    "    model = ImprovedLSTMModel(keypoint_size, skeleton_size, hidden_size, num_layers, num_classes).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    print(f\"모델을 에포크 {start_epoch}부터 계속 훈련합니다.\")\n",
    "else:\n",
    "    print(\"새 모델로 훈련을 시작합니다.\")\n",
    "    model = ImprovedLSTMModel(keypoint_size, skeleton_size, hidden_size, num_layers, num_classes).to(device)\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# 손실 함수 정의\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# 조기 종료 설정\n",
    "patience = 15  # 원하는 patience 값으로 설정\n",
    "early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "\n",
    "# 훈련 에포크 수 정의\n",
    "num_epochs = 100\n",
    "\n",
    "# 훈련 루프\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for batch_keypoints, batch_skeleton, batch_labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        batch_keypoints, batch_skeleton, batch_labels = batch_keypoints.to(device), batch_skeleton.to(device), batch_labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_keypoints, batch_skeleton)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_total += batch_labels.size(0)\n",
    "        train_correct += predicted.eq(batch_labels).sum().item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_accuracy = train_correct / train_total\n",
    "    \n",
    "    # 검증\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_keypoints, batch_skeleton, batch_labels in val_loader:\n",
    "            batch_keypoints, batch_skeleton, batch_labels = batch_keypoints.to(device), batch_skeleton.to(device), batch_labels.to(device)\n",
    "            \n",
    "            outputs = model(batch_keypoints, batch_skeleton)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += batch_labels.size(0)\n",
    "            val_correct += predicted.eq(batch_labels).sum().item()\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(batch_labels.cpu().numpy())\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = val_correct / val_total\n",
    "    \n",
    "    # F1 점수, 정밀도, 재현율 계산\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "    recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "    \n",
    "    # 학습률 조정\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # 모델 저장\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        save_model(epoch, model, optimizer, scheduler, train_loss, val_loss, f'improved_lstm_model_dog_epoch_{epoch+1}.pth', all_class_names)\n",
    "    \n",
    "    # 조기 종료 확인\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"조기 종료\")\n",
    "        break\n",
    "\n",
    "print(\"훈련 완료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
